# Multilayer Neural Network by Numpy

## Introduction
A small neural network framework implemented using Numpy implements linear layers, activation functions such as batch normalization, dropout, ReLu, Gelu, Softmax, and loss functions such as cross-entropy.

## Dictionary
```
activations.py -> activation functions includes relu, gelu, softmax
batchnorm.py -> batchnorm layer
classification.py -> main file, train and test model
cross_entropy.py -> cross_entropy function
data -> train and test data
dropout.py -> drop out layer
graphing.py -> Visualize model metrics
hyperparam_result.txt -> model metrics of different hyperparameter combinations
inputnorm.py -> input data normalization
linear.py -> linear layer
model.py -> model backbone, initialize layers in it
module_result.txt -> model metrics of different modules
optimizer.py -> optimizer funcations includes SGD, Momentum, Adam 
parameter.py -> basic parameter class
requirements.txt -> project env reuqirements.txt
```